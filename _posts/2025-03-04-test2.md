---
layout: single
title:  "Alexnet 구현하기"
categories: coding
tag: [python, blog, jupyter]
toc: true
author_profile: false
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


# **1. Alexnet**

AlexNet은 2012년 ILSVRC(ImageNet Large Scale Visual Recognition Challenge)에서 우승한 딥러닝 모델로, 딥러닝의 대중화를 이끈 중요한 합성곱 신경망(CNN)입니다. 이 모델은 8개의 레이어(5개의 합성곱 레이어와 3개의 완전 연결 레이어)로 구성되어 있으며, ReLU 활성화 함수, 드롭아웃(dropout), 데이터 증강(data augmentation) 등을 사용해 과적합을 방지하고 학습 성능을 향상시켰습니다. AlexNet은 대규모 데이터셋과 GPU 병렬 연산을 활용해 1,000개의 클래스 분류 문제에서 top-1, top-5 error rates가 각각 37.5%, 17.5%로 뛰어난 성능을 보여, 컴퓨터 비전에서 딥러닝이 표준 기법으로 자리 잡는 데 기여했습니다. 이 성과는 당시 기준으로 매우 뛰어난 결과였습니다. 특히 AlexNet은 이전에 사용된 전통적인 머신러닝 방법론보다 훨씬 큰 차이로 성능을 끌어올리며, 딥러닝의 가능성을 보여주었습니다. [논문 링크](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)



<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdcw1wn%2FbtsLNY2WjZf%2FXQN2C14pCONIY0sEarroV1%2Fimg.png'>


### ImageNet LSVRC



ImageNet LSVRC는 Large Scale Visual Recognition Challenge의 약자로, 이미지 인식 및 분류 기술을 겨루는 대회입니다. 2010년부터 매년 개최되었으며, ImageNet이라는 대규모 이미지 데이터셋을 기반으로 참가자들이 다양한 모델을 설계하고 경쟁했습니다.



* ImageNet 데이터셋: 약 1400만 장의 이미지를 포함하며, 1000개의 클래스(예: 고양이, 강아지, 자동차 등)로 분류된 대규모 이미지 데이터셋입니다.

* 목적: 컴퓨터 비전 및 딥러닝 기술의 발전을 촉진하고, 이미지 인식 분야에서 혁신적인 기술을 발견하는 것이 목표였습니다.

* LSVRC-2010: 이 대회에서 AlexNet이 2012년에 처음으로 딥러닝 기반 접근법을 사용해 뛰어난 성능을 보여줌으로써 딥러닝의 새로운 시대를 열었습니다.


### Error Rate



이미지 분류 모델의 성능을 평가하는 지표로, 모델이 이미지를 얼마나 정확히 분류했는지를 나타냅니다.



1. Top-1 Error Rate

    * 모델이 예측한 가장 높은 확률의 클래스(Top-1)가 정답이 아닐 확률입니다.

    * 예를 들어, 이미지에 "고양이"가 있고, 모델이 가장 높은 확률로 "강아지"라고 예측했다면, 이건 Top-1 에러입니다.​



2. Top-5 Error Rate

    * 모델이 예측한 상위 5개의 클래스 중 하나라도 정답에 포함되지 않았을 확률입니다.

    * 예를 들어, 이미지가 "고양이"인데 모델이 "강아지", "토끼", "고양이", "호랑이", "여우"를 상위 5개로 예측했다면, 이건 정답으로 간주됩니다.

    * Top-5를 사용하는 이유: 사람이 보기에 유사한 클래스(예: 치타와 표범)를 분류하는 것은 어렵기 때문에, 상위 5개 중에 정답이 있는지를 확인하는 방식으로 보다 실용적인 성능을 평가합니다.


# **2. CIFAR 데이터셋**

CIFAR 데이터셋은 torchvision 라이브러리에서 제공하는 이미지 데이터셋으로, 주로 딥러닝 모델의 학습 및 평가에 사용됩니다. CIFAR-10과 CIFAR-100 두 종류가 있으며, 각각 10개와 100개의 클래스에 대해 32x32 크기의 컬러 이미지로 구성됩니다. CIFAR-10은 클래스당 6,000개(총 60,000개)의 이미지로 이루어져 있으며, CIFAR-100은 클래스당 600개(총 60,000개)로 구성됩니다. PyTorch는 torchvision.datasets 모듈을 통해 이 데이터셋을 쉽게 불러올 수 있으며, 학습/테스트 데이터셋 분리, 데이터 증강(transforms), 정규화 등의 전처리를 지원합니다. 이 데이터셋은 이미지 분류 알고리즘을 실험하고 비교하는 데 널리 사용됩니다.


# **3. Alexnet 직접 구현(CIFAR 데이터셋 사용)**



```python
import numpy as np
import matplotlib.pyplot as plt

import torch
from torch.utils.data import DataLoader
from torch import nn

from torchvision import datasets
from torchvision.transforms import transforms
from torchvision.transforms.functional import to_pil_image
```


```python
train_img = datasets.CIFAR10(
    root='data',
    train=True,
    download=True,
    transform=transforms.ToTensor()
)
```

<pre>
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz
</pre>
<pre>
100%|██████████| 170M/170M [00:02<00:00, 66.9MB/s]
</pre>
<pre>
Extracting data/cifar-10-python.tar.gz to data
</pre>

```python
test_img = datasets.CIFAR10(
    root='data',
    train=False,
    download=True,
    transform=transforms.ToTensor()
)
```

<pre>
Files already downloaded and verified
</pre>

```python
test_img
```

<pre>
Dataset CIFAR10
    Number of datapoints: 10000
    Root location: data
    Split: Test
    StandardTransform
Transform: ToTensor()
</pre>

```python
train_img.data.shape[1]
```

<pre>
32
</pre>

```python
mean = train_img.data.mean(axis=(0,1,2)) / 255
std = train_img.data.std(axis=(0,1,2)) / 255
print(f'평균:{mean}, 표준편차:{std}')
```

<pre>
평균:[0.49139968 0.48215841 0.44653091], 표준편차:[0.24703223 0.24348513 0.26158784]
</pre>

```python
transform_train = transforms.Compose([
    transforms.RandomCrop(size=train_img.data.shape[1], padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean, std)
])
```


```python
train_img = datasets.CIFAR10(
    root='data',
    train=True,
    download=True,
    transform = transform_train
)

test_img = datasets.CIFAR10(
    root='data',
    train=False,
    download=True,
    transform = transform_train
)
```

<pre>
Files already downloaded and verified
Files already downloaded and verified
</pre>

```python
EPOCH = 10
BATCH_SIZE = 128
LEARNING_RATE = 1e-3
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using Device:', DEVICE)
```

<pre>
Using Device: cpu
</pre>

```python
train_loader = DataLoader(train_img, batch_size = BATCH_SIZE, shuffle = True)
test_loader = DataLoader(test_img, batch_size = BATCH_SIZE, shuffle = False)
```


```python
print(train_img, '\n------------------\n', test_img)
```

<pre>
Dataset CIFAR10
    Number of datapoints: 50000
    Root location: data
    Split: Train
    StandardTransform
Transform: Compose(
               RandomCrop(size=(32, 32), padding=4)
               RandomHorizontalFlip(p=0.5)
               ToTensor()
               Normalize(mean=[0.49139968 0.48215841 0.44653091], std=[0.24703223 0.24348513 0.26158784])
           ) 
------------------
 Dataset CIFAR10
    Number of datapoints: 10000
    Root location: data
    Split: Test
    StandardTransform
Transform: Compose(
               RandomCrop(size=(32, 32), padding=4)
               RandomHorizontalFlip(p=0.5)
               ToTensor()
               Normalize(mean=[0.49139968 0.48215841 0.44653091], std=[0.24703223 0.24348513 0.26158784])
           )
</pre>

```python
train_img[0]
```

<pre>
(tensor([[[-1.9892, -1.9892, -1.9892,  ..., -1.9892, -1.9892, -1.9892],
          [-1.9892, -1.9892, -1.9892,  ..., -1.9892, -1.9892, -1.9892],
          [-1.9892, -1.9892, -1.9892,  ..., -1.9892, -1.9892, -1.9892],
          ...,
          [-1.9892, -1.9892,  0.7412,  ..., -0.0684,  0.1539,  1.0111],
          [-1.9892, -1.9892,  1.2175,  ...,  0.1063,  0.7254,  1.4239],
          [-1.9892, -1.9892,  1.4397,  ...,  0.2809,  1.2334,  1.2810]],
 
         [[-1.9802, -1.9802, -1.9802,  ..., -1.9802, -1.9802, -1.9802],
          [-1.9802, -1.9802, -1.9802,  ..., -1.9802, -1.9802, -1.9802],
          [-1.9802, -1.9802, -1.9802,  ..., -1.9802, -1.9802, -1.9802],
          ...,
          [-1.9802, -1.9802,  0.0813,  ..., -0.4985, -0.3374,  0.5806],
          [-1.9802, -1.9802,  0.5484,  ..., -0.5307,  0.1296,  0.9672],
          [-1.9802, -1.9802,  0.8222,  ..., -0.2569,  0.7095,  0.8061]],
 
         [[-1.7070, -1.7070, -1.7070,  ..., -1.7070, -1.7070, -1.7070],
          [-1.7070, -1.7070, -1.7070,  ..., -1.7070, -1.7070, -1.7070],
          [-1.7070, -1.7070, -1.7070,  ..., -1.7070, -1.7070, -1.7070],
          ...,
          [-1.7070, -1.7070, -0.5677,  ..., -1.1223, -1.0474, -0.4027],
          [-1.7070, -1.7070, -0.4777,  ..., -1.0174, -0.6576, -0.1179],
          [-1.7070, -1.7070, -0.4027,  ..., -0.8525, -0.1779, -0.1329]]]),
 6)
</pre>

```python
train_features, train_labels = next(iter(train_loader))
print(f'Feature batch shape: {train_features.size()}')
print(f'Labels batch shape: {train_labels.size()}')
```

<pre>
Feature batch shape: torch.Size([128, 3, 32, 32])
Labels batch shape: torch.Size([128])
</pre>

```python
labels_map = {
    0: "plane",
    1: "car",
    2: "bird",
    3: "cat",
    4: "deer",
    5: "dog",
    6: "frog",
    7: "horse",
    8: "ship",
    9: "truck",
}
```


```python
def denormalize(img, mean, std):
    mean = torch.tensor(mean).view(3, 1, 1)
    std = torch.tensor(std).view(3, 1, 1)
    return img * std + mean
```


```python
figure = plt.figure(figsize = (8, 8))
cols, rows = 5, 5

for i in range(1, cols * rows +1):
    sample_idx = torch.randint(len(train_img), size=(1,)).item()
    img, label = train_img[sample_idx]
    # img = denormalize(img, mean, std)  # Normalize 복원
    figure.add_subplot(rows, cols, i)
    plt.title(labels_map[label])
    plt.axis('off')
    plt.imshow(to_pil_image(img))
plt.show()
```

<pre>
<Figure size 800x800 with 25 Axes>
</pre>

```python
```
